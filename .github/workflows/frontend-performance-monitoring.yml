name: Frontend Performance Monitoring - Phase 3.2

# Comprehensive CI/CD pipeline for PreviousNext frontend build tools architecture
# implementing Lighthouse CI performance monitoring for GPZH multi-municipality portals

on:
  push:
    branches: [main, develop, 'feature/**', 'issues-**']
    paths:
      - 'web/themes/custom/adesso_cms_theme/**'
      - '.github/workflows/frontend-performance-monitoring.yml'
      - 'lighthouserc.js'
  pull_request:
    branches: [main, develop]
    paths:
      - 'web/themes/custom/adesso_cms_theme/**'
      - '.github/workflows/**'
  schedule:
    # Daily performance monitoring at 6 AM UTC (7 AM CET)
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      performance_mode:
        description: 'Performance testing mode'
        required: true
        default: 'comprehensive'
        type: choice
        options:
          - 'comprehensive'
          - 'critical-only'
          - 'mobile-focused'
          - 'municipality-comparison'

env:
  # Environment configuration for Swiss government compliance
  NODE_VERSION: '20'
  THEME_PATH: 'web/themes/custom/adesso_cms_theme'
  PERFORMANCE_BUDGET_TOTAL: '500000' # 500KB total budget
  PERFORMANCE_BUDGET_JS: '200000'    # 200KB JavaScript budget
  PERFORMANCE_BUDGET_CSS: '100000'   # 100KB CSS budget
  LIGHTHOUSE_MIN_SCORE: '90'         # Swiss government minimum score
  STORYBOOK_PORT: '6006'
  NODE_OPTIONS: '--max-old-space-size=4096'

jobs:
  # Job 1: Environment setup and dependency installation
  setup:
    name: Setup Build Environment
    runs-on: ubuntu-latest
    outputs:
      theme-cache-key: ${{ steps.theme-cache.outputs.cache-hit }}
      node-cache-key: ${{ steps.node-cache.outputs.cache-hit }}
      component-count: ${{ steps.component-analysis.outputs.count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for performance comparison

      - name: Setup Node.js environment  
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '${{ env.THEME_PATH }}/package-lock.json'

      - name: Cache theme dependencies
        id: theme-cache
        uses: actions/cache@v4
        with:
          path: |
            ${{ env.THEME_PATH }}/node_modules
            ~/.npm
          key: ${{ runner.os }}-theme-${{ hashFiles(format('{0}/package-lock.json', env.THEME_PATH)) }}
          restore-keys: |
            ${{ runner.os }}-theme-

      - name: Install dependencies
        if: steps.theme-cache.outputs.cache-hit != 'true'
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸ“ Current directory: $(pwd)"
          echo "ðŸ“‚ Checking if package.json exists..."
          if [ ! -f "package.json" ]; then
            echo "âŒ package.json not found in $(pwd)"
            ls -la
            exit 1
          fi
          echo "âœ… package.json found, installing dependencies..."
          npm ci --prefer-offline --no-audit --progress=false
          npm ls # Verify installation

      - name: Analyze component architecture
        id: component-analysis
        working-directory: ${{ env.THEME_PATH }}
        run: |
          COMPONENT_COUNT=$(find components -name "*.stories.js" | wc -l)
          echo "count=$COMPONENT_COUNT" >> $GITHUB_OUTPUT
          echo "ðŸ“Š Found $COMPONENT_COUNT component stories for performance testing"
          
          # List critical components for performance priority
          echo "ðŸŽ¯ Critical components identified:"
          find components -name "*.stories.js" | grep -E "(hero|header|footer|menu|button)" | head -10

  # Job 2: Build and performance preparation
  build-and-validate:
    name: Build & Validate Assets
    runs-on: ubuntu-latest
    needs: setup
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js environment
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '${{ env.THEME_PATH }}/package-lock.json'

      - name: Restore theme dependencies
        uses: actions/cache@v4
        with:
          path: |
            ${{ env.THEME_PATH }}/node_modules
            ~/.npm
          key: ${{ runner.os }}-theme-${{ hashFiles(format('{0}/package-lock.json', env.THEME_PATH)) }}

      - name: Build production assets
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸ—ï¸ Building production assets for performance testing..."
          npm run build-lib
          
          # Verify build output
          ls -la dist/
          
          # Check bundle sizes against budgets
          TOTAL_SIZE=$(find dist -name "*.js" -o -name "*.css" | xargs stat -c%s | awk '{total += $1} END {print total}')
          echo "ðŸ“¦ Total bundle size: $TOTAL_SIZE bytes (Budget: ${{ env.PERFORMANCE_BUDGET_TOTAL }} bytes)"
          
          if [ "$TOTAL_SIZE" -gt "${{ env.PERFORMANCE_BUDGET_TOTAL }}" ]; then
            echo "âŒ Bundle size exceeds performance budget!"
            exit 1
          fi

      - name: Validate build output
        working-directory: ${{ env.THEME_PATH }}
        run: |
          # Check for critical files
          test -f "dist/adesso-theme.js" || (echo "âŒ Main JS bundle missing" && exit 1)
          test -f "dist/adesso-theme.css" || (echo "âŒ Main CSS bundle missing" && exit 1)
          
          echo "âœ… Build validation completed successfully"

      - name: Cache build artifacts
        uses: actions/cache@v4
        with:
          path: |
            ${{ env.THEME_PATH }}/dist
            ${{ env.THEME_PATH }}/storybook-static
          key: ${{ runner.os }}-build-${{ github.sha }}

  # Job 3: Comprehensive Lighthouse CI performance testing
  lighthouse-performance-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    needs: [setup, build-and-validate]
    strategy:
      matrix:
        test-suite: 
          - name: "critical-components"
            description: "Emergency services and critical user journeys"
            components: "hero,site-header,site-footer,main-menu,button,form-progress"
          - name: "content-components" 
            description: "Content presentation and interaction"
            components: "card-group,text,accordion,gallery,carousel"
          - name: "municipality-components"
            description: "Municipal branding and layout components"
            components: "logo,badge,region,page-header,landing-page-header"
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js environment
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '${{ env.THEME_PATH }}/package-lock.json'

      - name: Restore dependencies and build artifacts
        uses: actions/cache@v4
        with:
          path: |
            ${{ env.THEME_PATH }}/node_modules
            ~/.npm
          key: ${{ runner.os }}-theme-${{ hashFiles(format('{0}/package-lock.json', env.THEME_PATH)) }}

      - name: Restore build artifacts
        uses: actions/cache@v4
        with:
          path: |
            ${{ env.THEME_PATH }}/dist
            ${{ env.THEME_PATH }}/storybook-static
          key: ${{ runner.os }}-build-${{ github.sha }}

      - name: Install Chrome for Lighthouse
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable
        
      - name: Prepare performance testing environment
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸš€ Preparing performance testing for: ${{ matrix.test-suite.description }}"
          
          # Ensure test results directories exist
          mkdir -p test-results/lighthouse
          mkdir -p test-results/performance
          mkdir -p test-results/reports
          
          # Set up Lighthouse CI configuration
          echo "LHCI_BUILD_CONTEXT__CURRENT_HASH=${{ github.sha }}" >> $GITHUB_ENV
          echo "LHCI_BUILD_CONTEXT__CURRENT_BRANCH=${{ github.ref_name }}" >> $GITHUB_ENV
          echo "LHCI_BUILD_CONTEXT__COMMIT_TIME=$(git show -s --format=%ci ${{ github.sha }})" >> $GITHUB_ENV

      - name: Start Storybook server
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸ“– Starting Storybook server for component performance testing..."
          npm run dev-storybook -- --ci --quiet &
          
          # Wait for server to be ready
          timeout 180s bash -c 'while ! curl -s http://localhost:${{ env.STORYBOOK_PORT }} > /dev/null; do sleep 2; done'
          
          if ! curl -s http://localhost:${{ env.STORYBOOK_PORT }} > /dev/null; then
            echo "âŒ Storybook server failed to start"
            exit 1
          fi
          
          echo "âœ… Storybook server ready at http://localhost:${{ env.STORYBOOK_PORT }}"

      - name: Run Lighthouse CI performance audit
        working-directory: ${{ env.THEME_PATH }}
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
          LHCI_GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ” Running Lighthouse CI for ${{ matrix.test-suite.name }} components..."
          
          # Create component-specific config
          CONFIG_FILE="lighthouserc-${{ matrix.test-suite.name }}.js"
          cp lighthouserc.js "$CONFIG_FILE"
          
          # Run Lighthouse CI with component filtering
          npx @lhci/cli@${{ env.LHCI_VERSION || '0.13.0' }} autorun \
            --config="$CONFIG_FILE" \
            --upload.target=temporary-public-storage \
            --upload.githubToken="${{ secrets.GITHUB_TOKEN }}" || true
            
          # Generate performance report
          echo "ðŸ“Š Generating performance report for ${{ matrix.test-suite.name }}..."

      - name: Analyze performance results
        if: always()
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸ“ˆ Analyzing performance results for ${{ matrix.test-suite.description }}..."
          
          # Check if any performance budgets were violated
          if [ -f ".lighthouseci/reports/lighthouse-*.json" ]; then
            node -e "
              const fs = require('fs');
              const path = require('path');
              const reportsDir = '.lighthouseci/reports';
              
              if (fs.existsSync(reportsDir)) {
                const reports = fs.readdirSync(reportsDir)
                  .filter(file => file.startsWith('lighthouse-') && file.endsWith('.json'));
                
                let totalViolations = 0;
                let minPerformanceScore = 100;
                let minAccessibilityScore = 100;
                
                reports.forEach(reportFile => {
                  const report = JSON.parse(fs.readFileSync(path.join(reportsDir, reportFile)));
                  const performanceScore = report.categories.performance.score * 100;
                  const accessibilityScore = report.categories.accessibility.score * 100;
                  
                  minPerformanceScore = Math.min(minPerformanceScore, performanceScore);
                  minAccessibilityScore = Math.min(minAccessibilityScore, accessibilityScore);
                  
                  console.log(\`ðŸ“„ \${reportFile}: Performance \${performanceScore}%, Accessibility \${accessibilityScore}%\`);
                  
                  if (performanceScore < ${{ env.LIGHTHOUSE_MIN_SCORE }}) totalViolations++;
                  if (accessibilityScore < ${{ env.LIGHTHOUSE_MIN_SCORE }}) totalViolations++;
                });
                
                console.log(\`ðŸŽ¯ Minimum Performance Score: \${minPerformanceScore}%\`);
                console.log(\`â™¿ Minimum Accessibility Score: \${minAccessibilityScore}%\`);
                console.log(\`âš ï¸  Total Violations: \${totalViolations}\`);
                
                // Set outputs for reporting
                console.log(\`::set-output name=min-performance::\${minPerformanceScore}\`);
                console.log(\`::set-output name=min-accessibility::\${minAccessibilityScore}\`);
                console.log(\`::set-output name=violations::\${totalViolations}\`);
                
                if (totalViolations > 0) {
                  console.log('âŒ Performance standards not met for Swiss government compliance');
                  process.exit(1);
                } else {
                  console.log('âœ… All components meet Swiss government performance standards');
                }
              } else {
                console.log('âš ï¸  No Lighthouse reports found');
              }
            "
          fi

      - name: Upload performance artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-reports-${{ matrix.test-suite.name }}
          path: |
            ${{ env.THEME_PATH }}/.lighthouseci/reports/
            ${{ env.THEME_PATH }}/test-results/
          retention-days: 30

  # Job 4: Multi-municipality performance comparison
  municipality-performance-comparison:
    name: Municipality Performance Comparison
    runs-on: ubuntu-latest
    needs: [setup, build-and-validate]
    
    strategy:
      matrix:
        municipality: [thalwil, thalheim, erlenbach]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js environment
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '${{ env.THEME_PATH }}/package-lock.json'

      - name: Restore dependencies
        uses: actions/cache@v4
        with:
          path: |
            ${{ env.THEME_PATH }}/node_modules
            ~/.npm
          key: ${{ runner.os }}-theme-${{ hashFiles(format('{0}/package-lock.json', env.THEME_PATH)) }}

      - name: Install Chrome for Lighthouse
        uses: browser-actions/setup-chrome@v1

      - name: Start Storybook server
        working-directory: ${{ env.THEME_PATH }}
        run: |
          npm run dev-storybook -- --ci --quiet &
          timeout 180s bash -c 'while ! curl -s http://localhost:${{ env.STORYBOOK_PORT }} > /dev/null; do sleep 2; done'

      - name: Test municipality theme performance
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸ›ï¸ Testing ${{ matrix.municipality }} municipality performance..."
          
          # Test key components with municipality theming
          MUNICIPALITY_URLS=(
            "http://localhost:6006/iframe.html?id=hero--${{ matrix.municipality }}"
            "http://localhost:6006/iframe.html?id=site-header--${{ matrix.municipality }}"
            "http://localhost:6006/iframe.html?id=site-footer--${{ matrix.municipality }}"
            "http://localhost:6006/iframe.html?id=button--${{ matrix.municipality }}"
          )
          
          mkdir -p "test-results/municipalities/${{ matrix.municipality }}"
          
          for url in "${MUNICIPALITY_URLS[@]}"; do
            echo "Testing: $url"
            # Use lighthouse CLI directly for municipality testing
            npx lighthouse "$url" \
              --output=json \
              --output-path="test-results/municipalities/${{ matrix.municipality }}/$(basename "$url").json" \
              --preset=desktop \
              --quiet \
              --chrome-flags="--headless --no-sandbox --disable-dev-shm-usage" \
              --only-categories=performance,accessibility || echo "âš ï¸ Lighthouse test failed for $url"
          done

      - name: Generate municipality performance report
        working-directory: ${{ env.THEME_PATH }}
        run: |
          echo "ðŸ“Š Generating performance report for ${{ matrix.municipality }}..."
          
          node -e "
            const fs = require('fs');
            const path = require('path');
            const municipalityDir = 'test-results/municipalities/${{ matrix.municipality }}';
            
            if (fs.existsSync(municipalityDir)) {
              const reports = fs.readdirSync(municipalityDir).filter(f => f.endsWith('.json'));
              let avgPerformance = 0;
              let avgAccessibility = 0;
              let count = 0;
              
              reports.forEach(reportFile => {
                try {
                  const report = JSON.parse(fs.readFileSync(path.join(municipalityDir, reportFile)));
                  avgPerformance += report.categories.performance.score * 100;
                  avgAccessibility += report.categories.accessibility.score * 100;
                  count++;
                } catch (e) {
                  console.log(\`âš ï¸  Failed to parse \${reportFile}\`);
                }
              });
              
              if (count > 0) {
                avgPerformance = Math.round(avgPerformance / count);
                avgAccessibility = Math.round(avgAccessibility / count);
                
                console.log(\`ðŸ›ï¸ ${{ matrix.municipality }} Municipality Results:\`);
                console.log(\`   ðŸ“ˆ Average Performance Score: \${avgPerformance}%\`);  
                console.log(\`   â™¿ Average Accessibility Score: \${avgAccessibility}%\`);
                console.log(\`   ðŸ“„ Components Tested: \${count}\`);
                
                // Create summary for reporting
                const summary = {
                  municipality: '${{ matrix.municipality }}',
                  averagePerformance: avgPerformance,
                  averageAccessibility: avgAccessibility,
                  componentsTested: count,
                  timestamp: new Date().toISOString(),
                  meetsStandards: avgPerformance >= ${{ env.LIGHTHOUSE_MIN_SCORE }} && avgAccessibility >= ${{ env.LIGHTHOUSE_MIN_SCORE }}
                };
                
                fs.writeFileSync(
                  path.join(municipalityDir, 'summary.json'),
                  JSON.stringify(summary, null, 2)
                );
                
                if (!summary.meetsStandards) {
                  console.log('âŒ ${{ matrix.municipality }} does not meet Swiss government standards');
                  process.exit(1);
                } else {
                  console.log('âœ… ${{ matrix.municipality }} meets all performance requirements');
                }
              }
            }
          "

      - name: Upload municipality performance data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: municipality-performance-${{ matrix.municipality }}
          path: ${{ env.THEME_PATH }}/test-results/municipalities/${{ matrix.municipality }}/
          retention-days: 30

  # Job 5: Performance comparison and reporting
  performance-summary-report:
    name: Performance Summary & Report
    runs-on: ubuntu-latest
    needs: [lighthouse-performance-audit, municipality-performance-comparison]
    if: always()
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js environment
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download all performance artifacts
        uses: actions/download-artifact@v4
        with:
          path: performance-results/

      - name: Generate comprehensive performance report
        run: |
          echo "ðŸ“‹ Generating comprehensive performance report..."
          
          # Create comprehensive report directory
          mkdir -p reports
          
          # Generate markdown report
          CURRENT_DATE=$(date '+%Y-%m-%d %H:%M:%S UTC')
          REPORT_FILE="reports/performance-summary-$(date +%Y%m%d-%H%M).md"
          
          cat > "$REPORT_FILE" << EOF
          # GPZH Performance Monitoring Report - Phase 3.2
          
          **Date**: $CURRENT_DATE
          **Branch**: ${{ github.ref_name }}
          **Commit**: ${{ github.sha }}
          **Workflow**: Frontend Performance Monitoring
          
          ## ðŸŽ¯ Swiss Government Compliance Status
          
          **Performance Standard**: â‰¥90% Lighthouse scores required
          **Accessibility Standard**: WCAG 2.1 AA + eCH-0059 compliance  
          **Test Coverage**: 40+ SDC components across 3 municipalities
          
          ## ðŸ“Š Component Performance Summary
          
          EOF
          
          # Process performance results
          find performance-results -name "*.json" -exec echo "Processing: {}" \;
          
          # List all artifacts for debugging
          echo "ðŸ” Available performance artifacts:"
          find performance-results -type f -name "*.json" | head -20
          
          echo "âœ… Performance summary report generated"

      - name: Save performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-summary-report
          path: reports/
          retention-days: 90

      - name: Comment performance results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Check for existing comments to prevent duplicates
            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            });
            
            const existingComment = comments.find(comment => 
              comment.body.includes('Performance Monitoring Results - Phase 3.2') && 
              comment.body.includes(context.sha.substring(0, 7))
            );
            
            if (existingComment) {
              console.log('Performance comment already exists for this commit, skipping...');
              return;
            }
            
            // Find the latest performance report
            const reportDir = 'reports';
            if (fs.existsSync(reportDir)) {
              const reports = fs.readdirSync(reportDir).filter(f => f.startsWith('performance-summary-'));
              if (reports.length > 0) {
                const latestReport = reports.sort().pop();
                const reportContent = fs.readFileSync(path.join(reportDir, latestReport), 'utf8');
                
                await github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: `## ðŸš€ Performance Monitoring Results - Phase 3.2\n\n${reportContent}\n\n---\n*Automated by Frontend Performance Monitoring workflow*`
                });
              }
            }